---
layout: post
title: Hadoop源码环境搭建和调试-MAC环境
comments: true
categories: [Hadoop，Hadoop源码]
tags: [Hadoop源码]
---

## 安装protobuf
{% highlight vim %}
brew list   //列出通过brew安装的软件列表
brew search protobuf   //搜索protobuf
brew install protobuf   //安装protobuf
{% endhighlight %}
直接用brew install protobuf的话，会出现如下错误
{% highlight vim %}
curl: (7) Failed to connect to github-cloud.s3.amazonaws.com port 443: Operation timed out
Error: Failed to download resource "protobuf"
{% endhighlight %}
这个错误无法连接github-cloud.s3.amazonaws.com，好像是需要翻墙。
所以我换了一个方法。在github上的[protobuf源码](https://github.com/google/protobuf)。
{% highlight vim %}
git clone https://github.com/google/protobuf.git
{% endhighlight %}
在protobuf源码主页中，有[C++ installation Instruction](https://github.com/google/protobuf/blob/master/src/README.md)，这里提到，我们需要先安装
* autoconf
* automake
* libtool
* curl(mac自带)
* make
* g++(可以通过安装Xcode，来安装g++)
* unzip
这些都可以通过brew来安装。接着按照这儿Instruction往下走，需要执行./autogen.sh。但是这一步也需要我们翻墙。。。
所以我又换了个方式。https://developers.google.com/protocol-buffers/docs/downloads#latest-version，在这里，我下载了protobuf-2.6.1.tar.gz。要是不能下载的话，可以在[这里](https://yunpan.cn/cRYVA4w4FqVCX)下载，提取码为：15b8。（不要吐槽我用360云盘哦。。）下载之后解压，confige，make就可以了。具体如下：
{% highlight vim %}
tar zxf protobuf-2.6.1.tar.gz
cd protobuf-2.6.1
./configure --prefix=/usr/local/protobuf
.....
....
...
make check
...
..
.
make install //protobuf安装在/usr/local/protobuf下，把/usr/local/protobuf/bin加入到PATH中去。
...
..
.
protoc --version //查看版本。
{% endhighlight %}
后来发现protobuf-2.6在编译hadoop-common项目的时候会出错，因为hadoop-common项目制定protobuf的版本的2.5。（醉啦。。。）所以我又下载了protobuf-2.5，然后重复上面的步骤安装了protobuf-2.5。[protobuf-2.5.0.tar.gz的下载地址](https://yunpan.cn/cRYwdtemrEpYz) 提取码：e4a5

## 编译hadoop源码
我这里用的hadoop-2.6.4-src.tar.gz,[下载地址](https://yunpan.cn/cRYQjifRaAhts)，提取码为7429。也可以去hadoop官网下载。进入hadoop源码目录。mvn install -DskipTests
{% highlight java %}
Exception in thread "main" java.lang.AssertionError: Missing tools.jar at: /Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/Classes/classes.jar. Expression: file.exists()
	at org.codehaus.groovy.runtime.InvokerHelper.assertFailed(InvokerHelper.java:395)
	at org.codehaus.groovy.runtime.ScriptBytecodeAdapter.assertFailed(ScriptBytecodeAdapter.java:683)
	at org.codehaus.mojo.jspc.CompilationMojoSupport.findToolsJar(CompilationMojoSupport.groovy:371)
	at org.codehaus.mojo.jspc.CompilationMojoSupport.this$4$findToolsJar(CompilationMojoSupport.groovy)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:86)
	at groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:230)
	at groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:912)
	at org.codehaus.groovy.runtime.ScriptBytecodeAdapter.invokeMethodOnCurrentN(ScriptBytecodeAdapter.java:78)
	at org.codehaus.groovy.runtime.ScriptBytecodeAdapter.invokeMethodOnCurrent0(ScriptBytecodeAdapter.java:112)
	at org.codehaus.mojo.jspc.CompilationMojoSupport.execute(CompilationMojoSupport.groovy:318)
	at org.apache.maven.plugin.DefaultBuildPluginManager.executeMojo(DefaultBuildPluginManager.java:134)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:207)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:153)
	at org.apache.maven.lifecycle.internal.MojoExecutor.execute(MojoExecutor.java:145)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:116)
	at org.apache.maven.lifecycle.internal.LifecycleModuleBuilder.buildProject(LifecycleModuleBuilder.java:80)
	at org.apache.maven.lifecycle.internal.builder.singlethreaded.SingleThreadedBuilder.build(SingleThreadedBuilder.java:51)
	at org.apache.maven.lifecycle.internal.LifecycleStarter.execute(LifecycleStarter.java:128)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:307)
	at org.apache.maven.DefaultMaven.doExecute(DefaultMaven.java:193)
	at org.apache.maven.DefaultMaven.execute(DefaultMaven.java:106)
	at org.apache.maven.cli.MavenCli.execute(MavenCli.java:863)
	at org.apache.maven.cli.MavenCli.doMain(MavenCli.java:288)
	at org.apache.maven.cli.MavenCli.main(MavenCli.java:199)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:606)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launchEnhanced(Launcher.java:289)
	at org.codehaus.plexus.classworlds.launcher.Launcher.launch(Launcher.java:229)
	at org.codehaus.plexus.classworlds.launcher.Launcher.mainWithExitCode(Launcher.java:415)
	at org.codehaus.plexus.classworlds.launcher.Launcher.main(Launcher.java:356)
{% endhighlight %}
解决方法：到/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home目录下，创建Classes文件夹，在该文件下拷贝过来tools.jar。tools.jar本身是jdk安装目录自带的一个jar包。{% highlight vim %}
➜  Classes pwd
/Library/Java/JavaVirtualMachines/jdk1.7.0_79.jdk/Contents/Home/Classes
➜  Classes sudo ln -s ../lib/tools.jar classes.jar
{% endhighlight %}
之后，再到hadoop源码目录下mvn install -DskipTests，应该就会build success。
这里，使用mvn install -DskipTests的话，会把打包好的hadoop包放在~/.m2/设置的库当中。我们打包的命令如下：
{% highlight vim %}
➜  hadoop-2.6.4-src mvn clean package -DskipTests -Pdist 
{% endhighlight %}
其中 -Pdist表示，选择profile dist中的参数，设置打包方法。我们发现在hadoop-dist项目中的pom.xml中，配置了id为dist的profile。这样打包的结果是，在hadoop-dist项目中的target目录下，会生成hadoop binary文件。
{% highlight vim %}
➜  hadoop-2.6.4-src mvn clean package -DskipTests -Pdist -Dtar
{% endhighlight %}
其中，-Dtar应该对应dist profile中，id为tar的execution。加tar的话，最终hadoop-dist项目下，target中，生成的hadoop-{version}.tar.gz。

## Hadoop单机配置（非分布式版）
* 配置JAVA_HOME
* 配置HADOOP_HOME 
* 直接运行样例程序就可以了。样例程序是/hadoop-2.6.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar。运行如下
{% highlight vim %}
mkdir input
cd input
vim data    //这里创建hadoop程序的输入，一行一个单词，wordcount程序会数出每个单词出现了多少次
cd ..
hadoop jar ./hadoop-2.6.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar WordCount ./input ./output
{% endhighlight %}
>这里需要注意的是，./output文件夹不需要事先创建好，要是有output文件夹，则在跑程序之前删掉，否则会错，错误提示为output文件已存在。

## Hadoop伪分布式配置
Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。

Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/ 中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml 。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。

### Hadoop配置文件说明
Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml 中的配置项。core-site.xml一开始的内容为<configuration></configuration>。所以，我们在上一步中使用hadoop命令的过程中，默认在单机模式下运行。

此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。

### core-site.xml和hdfs-site.xml配置如下：
core-site.xml
{% highlight xml %}
<configuration>
        <property>
             <name>hadoop.tmp.dir</name>
             <value>file:/Users/zhengzhejun/software/hadoop-learn/hdfs_files</value>
             <description>Abase for other temporary directories.</description>
        </property>
        <property>
             <name>fs.defaultFS</name>
             <value>hdfs://localhost:9000</value>
        </property>
</configuration>
{% endhighlight %}
hdfs-site.xml
{% highlight xml %}
<configuration>
        <property>
             <name>dfs.replication</name>
             <value>1</value>
        </property>
        <property>
             <name>dfs.namenode.name.dir</name>
             <value>file:/Users/zhengzhejun/software/hadoop-learn/hdfs_files/name</value>
        </property>
        <property>
             <name>dfs.datanode.data.dir</name>
             <value>file:/Users/zhengzhejun/software/hadoop-learn/hdfs_files/data</value>
        </property>
</configuration>
{% endhighlight %}
### 格式化HDFS的目录，然后启动namenode，和datanode
{% highlight vim %}
hdfs namenode -format
${HADOOP_HOME}/sbin/start-dfs.sh
{% endhighlight %}
启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode” 和 “SecondaryNameNode”（如果 SecondaryNameNode 没有启动，请运行 sbin/stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。
成功启动后，可以访问 Web 界面 http://localhost:50070 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。

### 伪分布式下，跑测试程序
在伪分布式下，hadoop程序会从本地创建的hdfs中读取数据，并往hdfs中输出数据。所以，我们首先将输入数据上传到hdfs中，以让hadoop程序可以成功读取数据。
这里先列举几个操作hdfs的命令
{% highlight vim %}
hadoop fs -ls /   //列出目录/下的所有文件
hadoop fs -mkdir /input //创建/input文件夹
hadoop fs -put source_file dest_path  //将本地文件上传到hdfs的指定目录下
hadoop fs -get hdfs_file dest_path  //将hdfs上的文件下载到本地指定目录下
hadoop fs -cat hdfs_file   //查看hdfs上的指定文件
{% endhighlight %}
接下来，像在单机模式下建立input文件类似，我们先在hdfs上建立input文件，之后跑样例程序
{% highlight vim %}
hadoop fs -put ./etc/hadoop/*.xml /input
hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar grep /input /output 'dfs'
{% endhighlight %}
单机下伪分布式hadoop部署完成。

### 启动Yarn
> 伪分布式不启动yarn也可以，一般不影响程序执行

有的读者可能会疑惑，怎么启动 Hadoop 后，见不到书上所说的 JobTracker 和 TaskTracker，这是因为新版的 Hadoop 使用了新的 MapReduce 框架（MapReduce V2，也称为 YARN，Yet Another Resource Negotiator）。

YARN 是从 MapReduce 中分离出来的，负责资源管理与任务调度。YARN 运行于 MapReduce 之上，提供了高可用性、高扩展性，YARN 的更多介绍在此不展开，有兴趣的可查阅相关资料。

上述通过 ./sbin/start-dfs.sh 启动 Hadoop，仅仅是启动了 MapReduce 环境，我们可以启动 YARN ，让 YARN 来负责资源管理与任务调度。

首先修改配置文件 mapred-site.xml，这边需要先进行重命名：
{% highlight xml %}
<configuration>
        <property>
             <name>mapreduce.framework.name</name>
             <value>yarn</value>
        </property>
</configuration>
{% endhighlight %}

接着配置yarn-site.xml
{% highlight xml %}
<configuration>
        <property>
             <name>yarn.nodemanager.aux-services</name>
             <value>mapreduce_shuffle</value>
            </property>
</configuration>
{% endhighlight %}
启动yarn
{% highlight vim %}
./sbin/start-yarn.sh      # 启动YARN
./sbin/mr-jobhistory-daemon.sh start historyserver  # 开启历史服务器，才能在Web中查看任务运行情况
{% endhighlight %}

> 如果不想启动 YARN，务必把配置文件 mapred-site.xml 重命名，改成 mapred-site.xml.template，需要用时改回来就行。否则在该配置文件存在，而未开启 YARN 的情况下，运行程序会提示 “Retrying connect to server: 0.0.0.0/0.0.0.0:8032” 的错误，这也是为何该配置文件初始文件名为 mapred-site.xml.template。

接下来运行hadoop的workcount示例程序
{% highlight vim %}
hadoop jar ./hadoop-2.6.4/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.4.jar wordcount input output
{% endhighlight %}
这里，参数为input，在hdfs上对应的路径为/user/your-user-name/input/。所以，我们要在为/user/your-user-name/input/放入我们的数据。
另外，直接运行示例程序，发生了如下错误。
{% highlight java %}
16/06/15 23:02:38 INFO mapreduce.Job: Job job_1465999666813_0007 failed with state FAILED due to: Application application_1465999666813_0007 failed 2 times due to AM Container for appattempt_1465999666813_0007_000002 exited with  exitCode: 127
For more detailed output, check application tracking page:http://MacBook-Pro-2.local:8088/proxy/application_1465999666813_0007/Then, click on links to logs of each attempt.
Diagnostics: Exception from container-launch.
Container id: container_1465999666813_0007_02_000001
Exit code: 127
Stack trace: ExitCodeException exitCode=127:
	at org.apache.hadoop.util.Shell.runCommand(Shell.java:538)
	at org.apache.hadoop.util.Shell.run(Shell.java:455)
	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:715)
	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:212)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302)
	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)


Container exited with a non-zero exit code 127
Failing this attempt. Failing the application.
16/06/15 23:02:38 INFO mapreduce.Job: Counters: 0
{% endhighlight %}
在localhost:8088中查找这个失败的job，查看其log，可以发现错误如下:
{% highlight vim %}
/bin/bash: /bin/java: No such file or directory
{% endhighlight %}
这个问题google了一下，说是yarn管理的节点机器中，没有/bin/java文件。这里解决方法是
{% highlight vim %}
sudo ln -s /usr/bin/java /bin/java
{% endhighlight %}
之后重新提交任务，就可以成功了。

未完待续。。。（读一下示例程序中grep和wordcount的输入输出目录的设置, java的tools.jar包的路径问题，在启动yarn之后，为什么会出现/bin/java文件不存在的问题）




## 参考文献
* <https://www.zybuluo.com/sasaki/note/374808>
* <http://note.youdao.com/share/?id=f176a9b98eb67a3bcd88802298f61cd3&type=note#/>
* <http://www.powerxing.com/install-hadoop/>
